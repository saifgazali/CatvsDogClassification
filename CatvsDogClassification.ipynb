{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CatvsDogClassification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj8ykf3bB-ud"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xsku0IsB-um",
        "outputId": "33a544f8-ed96-4e0b-af11-d16ea6c8425e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1M28k8LB-up"
      },
      "source": [
        "# Data PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKrBUbmrB-us",
        "outputId": "ca9e5bc7-3573-4cfd-9ad9-33d8868b8ceb"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'dataset/training_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary') # we have binary value i.e cat or fog"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxyRBN2YB-uu",
        "outputId": "49098e57-b21a-414f-daba-15320eef852e"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'dataset/test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncn017JwB-uw"
      },
      "source": [
        "# Building the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEvBI7MfB-uy"
      },
      "source": [
        "cnn = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuhvgC6CB-uz"
      },
      "source": [
        "### convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCAsmR_mB-u1"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=2,activation='relu',input_shape=[64,64,3])) # filters - no of filters, kernel_size - size of the feature,strides - after each iteration after how many cell we consider the matrix for multiplication "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJPDQZ8zB-u2"
      },
      "source": [
        "### pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IMMqVbeB-u3"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEupKnMsB-u4"
      },
      "source": [
        "### 2nd Convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg7wtmaoB-u5"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=2,activation='relu')) # filters - no of filters, kernel_size - size of the feature,strides - after each iteration after how many cell we consider the matrix for multiplication \n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdQDqJzIB-u6"
      },
      "source": [
        "### Flattening\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VIAO5sIB-u7"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li50WdtaB-u8"
      },
      "source": [
        "### Full connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKMuSk3aB-u9"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=6,activation='relu')) #input layer\n",
        "cnn.add(tf.keras.layers.Dense(units=6,activation='relu')) # hidden layer\n",
        "cnn.add((tf.keras.layers.Dense(units=1,activation='sigmoid'))) # output layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XDPsc8LB-u-"
      },
      "source": [
        "### Training the CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hufoy3-CB-u-"
      },
      "source": [
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_hHgaypB-u_",
        "outputId": "6f002008-1454-4f1d-e74f-17567a9f196f"
      },
      "source": [
        "cnn.fit(x = train_generator,validation_data = validation_generator,epochs=10) # training the cnn on the training set and evaluating it on the test set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 459s 2s/step - loss: 0.6925 - accuracy: 0.5108 - val_loss: 0.6833 - val_accuracy: 0.5235\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 65s 260ms/step - loss: 0.6728 - accuracy: 0.5822 - val_loss: 0.6566 - val_accuracy: 0.6195\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 65s 261ms/step - loss: 0.6252 - accuracy: 0.6534 - val_loss: 0.6370 - val_accuracy: 0.6410\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 64s 258ms/step - loss: 0.5935 - accuracy: 0.6840 - val_loss: 0.6263 - val_accuracy: 0.6540\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 64s 257ms/step - loss: 0.5821 - accuracy: 0.6878 - val_loss: 0.5917 - val_accuracy: 0.6925\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 63s 252ms/step - loss: 0.5485 - accuracy: 0.7226 - val_loss: 0.5439 - val_accuracy: 0.7260\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 60s 242ms/step - loss: 0.5362 - accuracy: 0.7288 - val_loss: 0.5240 - val_accuracy: 0.7415\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.5346 - accuracy: 0.7426 - val_loss: 0.5160 - val_accuracy: 0.7455\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 57s 227ms/step - loss: 0.5226 - accuracy: 0.7390 - val_loss: 0.5263 - val_accuracy: 0.7320\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.5220 - accuracy: 0.7403 - val_loss: 0.5157 - val_accuracy: 0.7455\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x23ddea5ebe0>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta_HGt0fB-vA"
      },
      "source": [
        "### Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5HXXsOB-vB"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('dataset/single_prediction/aff.jpg',target_size= (64,64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0) # while processign we created batches on which cnn was trained, hence we an extra dimension of our batch.\n",
        "result = cnn.predict(test_image)\n",
        "\n",
        "train_generator.class_indices\n",
        "if(result[0][0]) == 1: #accessign the batch then the first element\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz2xBUkXB-vC",
        "outputId": "b7b635d4-301e-4d07-f721-91c9ae446c63"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxVs4-mbB-vD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrOmUXPjB-vD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ3hpxsTB-vD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}